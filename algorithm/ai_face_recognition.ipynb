{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "# Import TensorFlow and tf.keras\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import models\n",
    "from keras._tf_keras.keras.preprocessing import image\n",
    "from keras._tf_keras.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Input, Dense, Activation, Flatten, Conv2D\n",
    "from tensorflow.python.keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "from tensorflow.python.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras._tf_keras.keras.optimizers import Adam, SGD\n",
    "from keras._tf_keras.keras.applications import mobilenet\n",
    "from keras._tf_keras.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = r\"D:\\DoAnChuyenNganh_TTNT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Ariel_Sharon</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Colin_Powell</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>Donald_Rumsfeld</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>George_W_Bush</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>Gerhard_Schroeder</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  images\n",
       "373        Ariel_Sharon      77\n",
       "1047       Colin_Powell     236\n",
       "1404    Donald_Rumsfeld     121\n",
       "1871      George_W_Bush     530\n",
       "1892  Gerhard_Schroeder     109"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load only persons with more than \"number_of_images\"\n",
    "number_of_images = 50\n",
    "aug_multiplier = 10\n",
    "iter_csv = pd.read_csv(inputPath+\"/lfw_allnames.csv\", iterator=True, chunksize=1000)\n",
    "df = pd.concat([chunk[chunk['images'] > number_of_images] for chunk in iter_csv])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DoAnChuyenNganh_TTNT/lfw_funneled/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesFolder = inputPath+\"/lfw_funneled/\"\n",
    "imagesFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    print(y.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_len = (df.shape[0]*number_of_images*aug_multiplier)-(number_of_images*df.shape[0])\n",
    "y_tr = [\"\" for x in range(tr_len)]\n",
    "\n",
    "ts_len = df.shape[0]*number_of_images\n",
    "y_ts = [\"\" for x in range(ts_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373          Ariel_Sharon\n",
       "1047         Colin_Powell\n",
       "1404      Donald_Rumsfeld\n",
       "1871        George_W_Bush\n",
       "1892    Gerhard_Schroeder\n",
       "2175          Hugo_Chavez\n",
       "2288       Jacques_Chirac\n",
       "2468        Jean_Chretien\n",
       "2682        John_Ashcroft\n",
       "2941    Junichiro_Koizumi\n",
       "4963      Serena_Williams\n",
       "5458           Tony_Blair\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5400"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   9,  12,  39,  44,  49,  70,  79,  83, 100, 111, 115, 123,\n",
       "       138, 139, 144, 185, 189, 211, 212, 233, 234, 268, 279, 285, 310,\n",
       "       313, 330, 342, 359, 365, 366, 368, 376, 377, 397, 402, 409, 411,\n",
       "       426, 428, 430, 434, 446, 456, 461, 467, 469, 483, 495])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = default_rng()\n",
    "X_rand = rng.choice(number_of_images*aug_multiplier, size=number_of_images, replace=False)\n",
    "X_rand.sort()\n",
    "X_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareImages(df, m):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((tr_len, 250, 250, 3))\n",
    "    X_test = np.zeros((ts_len, 250, 250, 3))\n",
    "    \n",
    "    count = 0\n",
    "    ts_idx = 0\n",
    "    tr_idx = 0\n",
    "    \n",
    "    for personFolder in df['name']:\n",
    "        print(personFolder)\n",
    "        #count = 0\n",
    "        rng = default_rng()\n",
    "        X_rand = rng.choice(number_of_images*aug_multiplier, size=number_of_images, replace=False)\n",
    "        X_rand.sort()\n",
    "        rand_idx = 0\n",
    "        person_images_idx = 0\n",
    "        for img in os.listdir(imagesFolder+\"/\"+personFolder):\n",
    "            \n",
    "            #load images into images of size 100x100x3\n",
    "            img = image.load_img(imagesFolder+personFolder+\"/\"+img, target_size=(250, 250, 3))\n",
    "            x = image.img_to_array(img)\n",
    "            x = preprocess_input(x)\n",
    "            if (person_images_idx == X_rand[rand_idx]):\n",
    "                X_test[ts_idx] = x\n",
    "                y_ts[ts_idx] = personFolder\n",
    "                ts_idx += 1\n",
    "                #print(ts_idx)\n",
    "                if rand_idx<number_of_images-1:\n",
    "                    rand_idx += 1\n",
    "                \n",
    "            else:\n",
    "                X_train[tr_idx] = x\n",
    "                #print(\"else\\n\")\n",
    "                y_tr[tr_idx] = personFolder\n",
    "                tr_idx += 1\n",
    "            count += 1\n",
    "            person_images_idx += 1\n",
    "            #print(count)\n",
    "            if (count % ((number_of_images*aug_multiplier)) == 0):\n",
    "                print(\"Processing image: \", count, \", \", img)\n",
    "                break\n",
    "            \n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Ariel_Sharon\n",
      "Colin_Powell\n",
      "Donald_Rumsfeld\n",
      "George_W_Bush\n",
      "Processing image:  500 ,  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=250x250 at 0x13536472CE0>\n",
      "Gerhard_Schroeder\n",
      "Hugo_Chavez\n",
      "Jacques_Chirac\n",
      "Jean_Chretien\n",
      "John_Ashcroft\n",
      "Junichiro_Koizumi\n",
      "Serena_Williams\n",
      "Tony_Blair\n",
      "Processing image:  1000 ,  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=250x250 at 0x13536472CE0>\n",
      "[1 1 1 ... 0 0 0]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "(5400, 13)\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  5\n",
      "  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  7  7  7  8  8  8  8  8\n",
      "  8  8  8  8  9  9  9  9  9 10 10 10 10 10 11 11 11 11 11 12 12  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "(600, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "373          Ariel_Sharon\n",
       "1047         Colin_Powell\n",
       "1404      Donald_Rumsfeld\n",
       "1871        George_W_Bush\n",
       "1892    Gerhard_Schroeder\n",
       "2175          Hugo_Chavez\n",
       "2288       Jacques_Chirac\n",
       "2468        Jean_Chretien\n",
       "2682        John_Ashcroft\n",
       "2941    Junichiro_Koizumi\n",
       "4963      Serena_Williams\n",
       "5458           Tony_Blair\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test = prepareImages(df, df.shape[0]*number_of_images*aug_multiplier)\n",
    "\n",
    "y_train = prepare_labels(y_tr)\n",
    "\n",
    "y_test = prepare_labels(y_ts)\n",
    "\n",
    "df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 13)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 250, 250, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras._tf_keras.keras.preprocessing.image import ImageDataGenerator\n",
    "# create a data generator\n",
    "datagen = ImageDataGenerator()\n",
    "print(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_classes = y_train.shape[1]\n",
    "model = mobilenet.MobileNet(input_shape=(250, 250, 3), weights=None, include_top=True, alpha=1., classes=nr_classes)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0008), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy])\n",
    "#model.load_model(\"AI\\algorithm\\working/model_25gpunotop.h5\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS=100\n",
    "steps = len(X_train) / BS\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = len(X_train) / BS\n",
    "\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=1)\n",
    "# history = model.fit(datagen.flow(X_train, y_train, batch_size=BS), validation_data=(X_test, y_test), epochs=1, verbose=1)\n",
    "# model.save(r\"../working/model_25gpunotop.h5\")\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=BS), validation_data=(X_test, y_test), epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.python.keras.models import load_model  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_deteactor = cv2.CascadeClassifier(r\"D:\\DoAnChuyenNganh_TTNT\\AI\\algorithm\\haarcascades\\haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "# Load model  \n",
    "model = load_model(r\"D:\\DoAnChuyenNganh_TTNT\\AI\\algorithm\\AI\\algorithm\\working\\model_25gpunotop.h5\")  \n",
    "\n",
    "# Mở camera  \n",
    "camera = cv2.VideoCapture(0)  \n",
    "\n",
    "while True:  \n",
    "    ok, frame = camera.read()  \n",
    "    if not ok:  \n",
    "        print(\"Failed to capture video\")  \n",
    "        break  \n",
    "    \n",
    "    # Phát hiện khuôn mặt  \n",
    "    faces = face_deteactor.detectMultiScale(frame, 1.3, 5)  \n",
    "\n",
    "    for (x, y, w, h) in faces:  \n",
    "        roi = cv2.resize(frame[y:y+h, x:x+w], (250, 250))  # Resize mẫu khuôn mặt  \n",
    "        roi = roi / 255.0  # Chuẩn hóa dữ liệu (nếu mô hình đã được huấn luyện với dữ liệu chuẩn hóa)  \n",
    "        roi = np.reshape(roi, (-1, 250, 250, 3))  # Thay đổi kích thước về dạng (batch_size, height, width, channels)  \n",
    "        \n",
    "        # Dự đoán  \n",
    "        result = model.predict(roi)  \n",
    "        \n",
    "        # Xử lý kết quả dự đoán  \n",
    "        predicted_class = np.argmax(result, axis=1)  # Lấy lớp dự đoán cao nhất  \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 255, 50), 1)  \n",
    "        cv2.putText(frame, str(predicted_class), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)  # Vẽ nhãn  \n",
    "\n",
    "    # Hiện thị khung hình  \n",
    "    cv2.imshow('frame', frame)  \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  \n",
    "        break  \n",
    "\n",
    "# Giải phóng camera  \n",
    "camera.release()  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models.load_model(r\"D:\\DoAnChuyenNganh_TTNT\\AI\\algorithm\\AI\\algorithm\\working\\model_25gpunotop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('Model categorical accuracy')\n",
    "plt.ylabel('categorical accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model validation categorical accuracy')\n",
    "plt.ylabel('Val categorical accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(r\"D:\\DoAnChuyenNganh_TTNT\\testimage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r\"D:\\DoAnChuyenNganh_TTNT\\lfw_funneled\\Serena_Williams\\Serena_Williams_0052.jpg\", target_size=(250, 250, 3))\n",
    "x = image.img_to_array(img)\n",
    "Xnew = x\n",
    "#Xnew = preprocess_input(x)\n",
    "Xtest = np.expand_dims(Xnew, axis=0)\n",
    "ynew = model.predict(Xtest)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = mobilenet.MobileNet(input_shape=(224, 224, 3),include_top=True, alpha=1., weights=None, classes=y.shape[1])\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "#              metrics=[categorical_crossentropy, categorical_accuracy, top_5_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = \"model_5adamaug00002knopre\"\n",
    "\n",
    "# model.load_weights(\"../input/model-50/model_50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = np.expand_dims(Xnew, axis=0)\n",
    "ynew = model.predict(Xtest)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Set quantize to true \n",
    "#converter.post_training_quantize=True\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "# Create the tflite model file\n",
    "tflite_model_name = out_name+\".tflite\"\n",
    "open(tflite_model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_encoder.inverse_transform(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(out_name+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(out_name+\".weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, out_name+\"_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "        \n",
    "make_tarfile(out_name+\"Tar\", r\"D:\\DoAnChuyenNganh_TTNT\\AI\\algorithm\\model_50adamaug00002knopre_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97568"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a converter\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(r\"D:\\DoAnChuyenNganh_TTNT\\AI\\algorithm\\model_50adamaug00002knopre_saved\")\n",
    "# Set quantize to true \n",
    "#converter.post_training_quantize=True\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "# Create the tflite model file\n",
    "tflite_model_name = out_name+\"fromSaved.tflite\"\n",
    "open(tflite_model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(out_name+\".h5\", include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Unrecognized keyword arguments:', dict_keys(['batch_shape']))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \n\u001b[0;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDoAnChuyenNganh_TTNT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mworking\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel_25gpunotop.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Truy cap den duong dan thu muc anh\u001b[39;00m\n\u001b[0;32m     11\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDoAnChuyenNganh_TTNT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlfw_funneled\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py:197\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m load_context\u001b[38;5;241m.\u001b[39mload_context(options):\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    196\u001b[0m       (\u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile) \u001b[38;5;129;01mor\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mis_hdf5(filepath))):\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m   filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:180\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    178\u001b[0m   model_config \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    179\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(model_config)\n\u001b[1;32m--> 180\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_config_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[0;32m    184\u001b[0m load_weights_from_hdf5_group(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m], model\u001b[38;5;241m.\u001b[39mlayers)\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\model_config.py:50\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     46\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`model_from_config` expects a dictionary, not a list. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     47\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaybe you meant to use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     48\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Sequential.from_config(config)`?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py:113\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    Layer instance (may be Model, Sequential, Network, Layer...)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m populate_deserializable_objects()\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:665\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    662\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m--> 665\u001b[0m   deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_GLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    669\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    671\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m CustomObjectScope(custom_objects):\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:668\u001b[0m, in \u001b[0;36mFunctional.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates a Model from its config (output of `get_config()`).\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    ValueError: In case of improperly formatted config dict.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mSharedObjectLoadingScope():\n\u001b[1;32m--> 668\u001b[0m   input_tensors, output_tensors, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(inputs\u001b[38;5;241m=\u001b[39minput_tensors, outputs\u001b[38;5;241m=\u001b[39moutput_tensors,\n\u001b[0;32m    671\u001b[0m               name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    672\u001b[0m   connect_ancillary_layers(model, created_layers)\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1279\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m-> 1279\u001b[0m   \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1261\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_layer\u001b[1;34m(layer_data)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1258\u001b[0m   \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize \u001b[38;5;28;01mas\u001b[39;00m deserialize_layer  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m-> 1261\u001b[0m   layer \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1262\u001b[0m   created_layers[layer_name] \u001b[38;5;241m=\u001b[39m layer\n\u001b[0;32m   1264\u001b[0m node_count_by_layer[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(_should_skip_first_node(layer))\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py:113\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    Layer instance (may be Model, Sequential, Network, Layer...)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m populate_deserializable_objects()\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:672\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    670\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m CustomObjectScope(custom_objects):\n\u001b[1;32m--> 672\u001b[0m       deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# in this case by convention `config` holds\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;66;03m# the kwargs of the function.\u001b[39;00m\n\u001b[0;32m    677\u001b[0m   custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:753\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config):\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a layer from its config.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \n\u001b[0;32m    741\u001b[0m \u001b[38;5;124;03m  This method is the reverse of `get_config`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;124;03m      A layer instance.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 753\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "File \u001b[1;32md:\\DoAnChuyenNganh_TTNT\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py:135\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m batch_input_shape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments:\u001b[39m\u001b[38;5;124m'\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;129;01mand\u001b[39;00m ragged:\n\u001b[0;32m    138\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot set both sparse and ragged to True in a Keras input.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: ('Unrecognized keyword arguments:', dict_keys(['batch_shape']))"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import numpy as np  \n",
    "from tensorflow.python.keras.models import load_model  \n",
    "from keras._tf_keras.keras.preprocessing.image import img_to_array  \n",
    "import pandas as pd  \n",
    "\n",
    "model_path = r\"D:\\DoAnChuyenNganh_TTNT\\AI\\algorithm\\AI\\algorithm\\working\\model_25gpunotop.h5\"  \n",
    "model = load_model(model_path)  \n",
    "\n",
    "# Truy cap den duong dan thu muc anh\n",
    "root_dir = r'D:\\DoAnChuyenNganh_TTNT\\lfw_funneled'\n",
    "\n",
    "label_name = os.listdir(root_dir)\n",
    "print(label_name)\n",
    "print(len(label_name))\n",
    "\n",
    "# Face detector  \n",
    "face_detector = cv2.CascadeClassifier(r\"D:\\DoAnChuyenNganh_TTNT\\AI\\algorithm\\haarcascades\\haarcascade_frontalface_alt.xml\")  \n",
    "\n",
    "camera = cv2.VideoCapture(0)  \n",
    "\n",
    "while True:  \n",
    "    ok, frame = camera.read()  \n",
    "    if not ok:  \n",
    "        print(\"Failed to capture video\")  \n",
    "        break  \n",
    "\n",
    "    faces = face_detector.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=5)  \n",
    "    \n",
    "    for (x, y, w, h) in faces:  \n",
    "        roi = cv2.resize(frame[y:y+h, x:x+w], (250, 250)) \n",
    "        roi = roi.astype(\"float32\") / 255.0 \n",
    "        roi = img_to_array(roi)  \n",
    "        roi = np.expand_dims(roi, axis=0) \n",
    "\n",
    "        # Dự đoán  \n",
    "        result = model.predict(roi)  \n",
    "        predicted_class_index = np.argmax(result, axis=1)[0]  \n",
    "        \n",
    "        predicted_name = label_name[predicted_class_index]  \n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (128, 255, 50), 2)  \n",
    "        cv2.putText(frame, predicted_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)  \n",
    "\n",
    "    cv2.imshow('frame', frame)  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  \n",
    "        break  \n",
    "\n",
    "camera.release()  \n",
    "cv2.destroyAllWindows()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
